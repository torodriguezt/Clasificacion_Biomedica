{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0661d985",
   "metadata": {},
   "source": [
    "# Medical Text Classification with BERT\n",
    "\n",
    "## An√°lisis Integral de Clasificaci√≥n Biom√©dica\n",
    "\n",
    "Este notebook presenta un an√°lisis completo de clasificaci√≥n de textos m√©dicos utilizando modelos de transformers, espec√≠ficamente BERT adaptado para el dominio biom√©dico.\n",
    "\n",
    "### Objetivos:\n",
    "1. **An√°lisis Exploratorio**: Examinar la distribuci√≥n de datos y caracter√≠sticas del dataset\n",
    "2. **Preprocesamiento**: Limpiar y preparar los datos m√©dicos para el modelado\n",
    "3. **Modelado**: Implementar y entrenar m√∫ltiples modelos de clasificaci√≥n\n",
    "4. **Evaluaci√≥n**: Analizar el rendimiento y optimizar umbrales de decisi√≥n\n",
    "5. **Validaci√≥n**: Verificar la robustez del modelo final\n",
    "\n",
    "### Categor√≠as de Clasificaci√≥n:\n",
    "- **Cardiovascular**: Condiciones relacionadas con el coraz√≥n y sistema circulatorio\n",
    "- **Hepatorenal**: Patolog√≠as del h√≠gado y ri√±ones\n",
    "- **Neurol√≥gico**: Trastornos del sistema nervioso\n",
    "- **Oncol√≥gico**: Condiciones relacionadas con c√°ncer y tumores\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578a2db",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n del Entorno\n",
    "\n",
    "### Importaci√≥n de Librer√≠as y M√≥dulos Personalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de warnings y entorno\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuraci√≥n de matplotlib para mejores gr√°ficos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Agregar scripts al path\n",
    "scripts_path = Path('../scripts')\n",
    "if scripts_path.exists():\n",
    "    sys.path.append(str(scripts_path))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: scripts directory not found. Make sure to run this notebook from the project root.\")\n",
    "\n",
    "print(\"‚úÖ Environment configured successfully\")\n",
    "print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
    "print(f\"üêç Python version: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1da391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar m√≥dulos personalizados\n",
    "try:\n",
    "    from data_processing import (\n",
    "        load_medical_data, clean_medical_text, preprocess_labels,\n",
    "        split_stratified_multilabel, analyze_label_distribution,\n",
    "        validate_dataset_integrity\n",
    "    )\n",
    "    \n",
    "    from visualization import (\n",
    "        plot_label_distribution, plot_text_length_analysis,\n",
    "        plot_correlation_heatmap, plot_word_clouds,\n",
    "        configure_plot_style, plot_roc_curves\n",
    "    )\n",
    "    \n",
    "    from model_utils import (\n",
    "        ImprovedMedicalBERT, MedicalDataset, EnsembleClassifier,\n",
    "        create_data_loaders, get_device_info\n",
    "    )\n",
    "    \n",
    "    from training_utils import (\n",
    "        train_bert_model, evaluate_model, save_model_artifacts,\n",
    "        load_model_artifacts, create_dummy_classifier\n",
    "    )\n",
    "    \n",
    "    from evaluation_utils import (\n",
    "        compute_multilabel_metrics, find_optimal_thresholds,\n",
    "        plot_confusion_matrices, plot_threshold_analysis,\n",
    "        analyze_prediction_errors\n",
    "    )\n",
    "    \n",
    "    from text_augmentation import (\n",
    "        MedicalTextAugmenter, apply_augmentation_pipeline\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ All custom modules imported successfully\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing custom modules: {e}\")\n",
    "    print(\"Make sure all script files are in the 'scripts' directory\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar estilo de visualizaci√≥n\n",
    "configure_plot_style()\n",
    "\n",
    "# Verificar disponibilidad de GPU\n",
    "device_info = get_device_info()\n",
    "print(f\"üñ•Ô∏è Device: {device_info['device']}\")\n",
    "if device_info['cuda_available']:\n",
    "    print(f\"üöÄ GPU: {device_info['gpu_name']}\")\n",
    "    print(f\"üíæ GPU Memory: {device_info['gpu_memory']:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU available, using CPU\")\n",
    "\n",
    "# Configuraci√≥n global\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "BATCH_SIZE = 16\n",
    "MAX_LENGTH = 512\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 3\n",
    "\n",
    "# Nombres de las categor√≠as\n",
    "LABEL_COLUMNS = ['cardiovascular', 'hepatorenal', 'neurologico', 'oncologico']\n",
    "\n",
    "print(\"\\nüîß Configuration:\")\n",
    "print(f\"   Random State: {RANDOM_STATE}\")\n",
    "print(f\"   Test Size: {TEST_SIZE}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Max Length: {MAX_LENGTH}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   Epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a6a6f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Carga y An√°lisis Exploratorio de Datos\n",
    "\n",
    "### 2.1 Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68485c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "data_file = 'challenge_data-18-ago.csv'\n",
    "\n",
    "try:\n",
    "    df = load_medical_data(data_file)\n",
    "    print(f\"‚úÖ Dataset loaded successfully\")\n",
    "    print(f\"üìä Shape: {df.shape}\")\n",
    "    print(f\"üìù Columns: {list(df.columns)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: File '{data_file}' not found\")\n",
    "    print(\"Please make sure the data file is in the current directory\")\n",
    "    sys.exit(1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar primeras filas\n",
    "print(\"üìã First 5 rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nüìä Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nüìà Descriptive Statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea059d6",
   "metadata": {},
   "source": [
    "### 2.2 An√°lisis de la Distribuci√≥n de Etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a958c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar distribuci√≥n de etiquetas\n",
    "label_stats = analyze_label_distribution(df, LABEL_COLUMNS)\n",
    "\n",
    "print(\"üè∑Ô∏è Label Distribution Analysis:\")\n",
    "print(f\"   Total samples: {label_stats['total_samples']}\")\n",
    "print(f\"   Samples with no labels: {label_stats['samples_no_labels']}\")\n",
    "print(f\"   Samples with multiple labels: {label_stats['samples_multiple_labels']}\")\n",
    "print(f\"   Average labels per sample: {label_stats['avg_labels_per_sample']:.2f}\")\n",
    "\n",
    "print(\"\\nüìä Individual Label Frequencies:\")\n",
    "for label, freq in label_stats['label_frequencies'].items():\n",
    "    percentage = (freq / label_stats['total_samples']) * 100\n",
    "    print(f\"   {label}: {freq} ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nüîó Label Co-occurrences:\")\n",
    "for pair, count in label_stats['label_cooccurrence'].items():\n",
    "    print(f\"   {pair}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuci√≥n de etiquetas\n",
    "plot_label_distribution(df, LABEL_COLUMNS, \n",
    "                       title=\"Distribuci√≥n de Categor√≠as M√©dicas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ea2c1",
   "metadata": {},
   "source": [
    "### 2.3 An√°lisis de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5996d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de longitud de texto\n",
    "plot_text_length_analysis(df, 'text', \n",
    "                          title=\"An√°lisis de Longitud de Textos M√©dicos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n entre etiquetas\n",
    "plot_correlation_heatmap(df, LABEL_COLUMNS, \n",
    "                         title=\"Correlaci√≥n entre Categor√≠as M√©dicas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3cfd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nubes de palabras por categor√≠a\n",
    "plot_word_clouds(df, 'text', LABEL_COLUMNS, \n",
    "                title=\"Palabras M√°s Frecuentes por Categor√≠a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f900666",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Preprocesamiento de Datos\n",
    "\n",
    "### 3.1 Limpieza de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd842259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar texto m√©dico\n",
    "print(\"üßπ Cleaning medical text...\")\n",
    "\n",
    "# Mostrar ejemplo antes de la limpieza\n",
    "sample_text = df['text'].iloc[0]\n",
    "print(f\"üìù Original text (first 200 chars):\\n{sample_text[:200]}...\\n\")\n",
    "\n",
    "# Aplicar limpieza\n",
    "df['text_clean'] = df['text'].apply(clean_medical_text)\n",
    "\n",
    "# Mostrar ejemplo despu√©s de la limpieza\n",
    "cleaned_text = df['text_clean'].iloc[0]\n",
    "print(f\"‚ú® Cleaned text (first 200 chars):\\n{cleaned_text[:200]}...\")\n",
    "\n",
    "# Estad√≠sticas de limpieza\n",
    "original_lengths = df['text'].str.len()\n",
    "cleaned_lengths = df['text_clean'].str.len()\n",
    "\n",
    "print(f\"\\nüìä Cleaning Statistics:\")\n",
    "print(f\"   Original avg length: {original_lengths.mean():.1f} chars\")\n",
    "print(f\"   Cleaned avg length: {cleaned_lengths.mean():.1f} chars\")\n",
    "print(f\"   Reduction: {((original_lengths.mean() - cleaned_lengths.mean()) / original_lengths.mean() * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4fc716",
   "metadata": {},
   "source": [
    "### 3.2 Preparaci√≥n de Etiquetas y Divisi√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23516c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar etiquetas\n",
    "print(\"üè∑Ô∏è Preparing labels...\")\n",
    "y = preprocess_labels(df, LABEL_COLUMNS)\n",
    "X = df['text_clean'].values\n",
    "\n",
    "print(f\"   Features shape: {X.shape}\")\n",
    "print(f\"   Labels shape: {y.shape}\")\n",
    "print(f\"   Label columns: {LABEL_COLUMNS}\")\n",
    "\n",
    "# Validar integridad del dataset\n",
    "validation_results = validate_dataset_integrity(df, 'text_clean', LABEL_COLUMNS)\n",
    "\n",
    "if validation_results['is_valid']:\n",
    "    print(\"‚úÖ Dataset validation passed\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset validation failed:\")\n",
    "    for issue in validation_results['issues']:\n",
    "        print(f\"   - {issue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9475d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n estratificada de datos\n",
    "print(\"üîÄ Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = split_stratified_multilabel(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"   Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"   Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"   Split ratio: {(1-TEST_SIZE)*100:.0f}% / {TEST_SIZE*100:.0f}%\")\n",
    "\n",
    "# Verificar distribuci√≥n en splits\n",
    "train_label_freq = y_train.sum(axis=0) / len(y_train)\n",
    "test_label_freq = y_test.sum(axis=0) / len(y_test)\n",
    "\n",
    "print(\"\\nüìä Label distribution in splits:\")\n",
    "for i, label in enumerate(LABEL_COLUMNS):\n",
    "    print(f\"   {label}: Train {train_label_freq[i]:.3f} | Test {test_label_freq[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d801df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Modelado y Entrenamiento\n",
    "\n",
    "### 4.1 Modelo Baseline (Dummy Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054fbbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y evaluar modelo dummy\n",
    "print(\"üéØ Training baseline model (Dummy Classifier)...\")\n",
    "\n",
    "dummy_model = create_dummy_classifier(strategy='most_frequent')\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluaci√≥n del modelo dummy\n",
    "y_pred_dummy = dummy_model.predict(X_test)\n",
    "\n",
    "# Calcular m√©tricas\n",
    "dummy_metrics = compute_multilabel_metrics(\n",
    "    y_test, y_pred_dummy, \n",
    "    class_names=LABEL_COLUMNS\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Dummy Classifier Results:\")\n",
    "print(f\"   F1 Macro: {dummy_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   F1 Weighted: {dummy_metrics['f1_weighted']:.4f}\")\n",
    "print(f\"   Hamming Loss: {dummy_metrics['hamming_loss']:.4f}\")\n",
    "print(f\"   Exact Match Ratio: {dummy_metrics['exact_match_ratio']:.4f}\")\n",
    "\n",
    "# Guardar resultados del baseline\n",
    "baseline_results = {\n",
    "    'model_name': 'Dummy Classifier',\n",
    "    'metrics': dummy_metrics,\n",
    "    'predictions': y_pred_dummy\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d648c4",
   "metadata": {},
   "source": [
    "### 4.2 Modelo DEMO (BERT Simplificado)\n",
    "\n",
    "**Nota**: Este es el modelo DEMO mencionado en la especificaci√≥n - un modelo BERT con configuraci√≥n simplificada para demostraci√≥n r√°pida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n para modelo DEMO\n",
    "DEMO_CONFIG = {\n",
    "    'epochs': 1,  # Solo 1 √©poca para demostraci√≥n\n",
    "    'batch_size': 8,  # Batch size m√°s peque√±o\n",
    "    'max_length': 256,  # Secuencias m√°s cortas\n",
    "    'learning_rate': 3e-5\n",
    "}\n",
    "\n",
    "print(f\"üöÄ Training DEMO model (BERT - Quick Demo)...\")\n",
    "print(f\"   Configuration: {DEMO_CONFIG}\")\n",
    "\n",
    "# Crear dataset para el modelo DEMO\n",
    "# Usar solo una muestra peque√±a para demostraci√≥n r√°pida\n",
    "demo_size = min(1000, len(X_train))  # M√°ximo 1000 muestras\n",
    "X_train_demo = X_train[:demo_size]\n",
    "y_train_demo = y_train[:demo_size]\n",
    "\n",
    "print(f\"   Using {demo_size} samples for quick demo\")\n",
    "\n",
    "# Crear data loaders para modelo DEMO\n",
    "train_loader_demo, _ = create_data_loaders(\n",
    "    X_train_demo, y_train_demo, X_test, y_test,\n",
    "    batch_size=DEMO_CONFIG['batch_size'],\n",
    "    max_length=DEMO_CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Crear modelo DEMO\n",
    "device = get_device_info()['device']\n",
    "demo_model = ImprovedMedicalBERT(\n",
    "    num_labels=len(LABEL_COLUMNS),\n",
    "    model_name='distilbert-base-uncased'  # Modelo m√°s r√°pido para demo\n",
    ").to(device)\n",
    "\n",
    "print(f\"   Model created on {device}\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in demo_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo DEMO\n",
    "demo_model, demo_training_history = train_bert_model(\n",
    "    model=demo_model,\n",
    "    train_loader=train_loader_demo,\n",
    "    val_loader=None,  # Sin validaci√≥n para demo r√°pido\n",
    "    epochs=DEMO_CONFIG['epochs'],\n",
    "    learning_rate=DEMO_CONFIG['learning_rate'],\n",
    "    device=device,\n",
    "    save_path=None  # No guardar para demo\n",
    ")\n",
    "\n",
    "print(\"‚úÖ DEMO model training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a6f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo DEMO\n",
    "print(\"üìä Evaluating DEMO model...\")\n",
    "\n",
    "# Crear data loader para evaluaci√≥n\n",
    "test_dataset = MedicalDataset(X_test, y_test, max_length=DEMO_CONFIG['max_length'])\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=DEMO_CONFIG['batch_size'], shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "demo_results = evaluate_model(demo_model, test_loader, device)\n",
    "\n",
    "print(\"\\nüìà DEMO Model Results:\")\n",
    "print(f\"   F1 Macro: {demo_results['f1_macro']:.4f}\")\n",
    "print(f\"   F1 Weighted: {demo_results['f1_weighted']:.4f}\")\n",
    "print(f\"   Hamming Loss: {demo_results['hamming_loss']:.4f}\")\n",
    "print(f\"   Exact Match Ratio: {demo_results['exact_match_ratio']:.4f}\")\n",
    "\n",
    "# Comparar con baseline\n",
    "improvement_f1 = demo_results['f1_weighted'] - dummy_metrics['f1_weighted']\n",
    "print(f\"\\nüéØ Improvement over baseline:\")\n",
    "print(f\"   F1 Weighted improvement: +{improvement_f1:.4f}\")\n",
    "print(f\"   Relative improvement: {(improvement_f1/dummy_metrics['f1_weighted']*100):.1f}%\")\n",
    "\n",
    "# Guardar resultados del DEMO\n",
    "demo_model_results = {\n",
    "    'model_name': 'BERT DEMO',\n",
    "    'metrics': demo_results,\n",
    "    'config': DEMO_CONFIG,\n",
    "    'training_samples': demo_size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1072ed3",
   "metadata": {},
   "source": [
    "### 4.3 Modelo Principal (ImprovedMedicalBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear data loaders para modelo principal\n",
    "print(\"üîÑ Creating data loaders for main model...\")\n",
    "\n",
    "train_loader, val_loader = create_data_loaders(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=MAX_LENGTH,\n",
    "    validation_split=0.2  # 20% para validaci√≥n\n",
    ")\n",
    "\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Crear modelo principal\n",
    "print(\"\\nüß† Creating main model (ImprovedMedicalBERT)...\")\n",
    "main_model = ImprovedMedicalBERT(\n",
    "    num_labels=len(LABEL_COLUMNS),\n",
    "    model_name='bert-base-uncased',\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "print(f\"   Model created on {device}\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in main_model.parameters()):,}\")\n",
    "print(f\"   Trainable parameters: {sum(p.numel() for p in main_model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo principal\n",
    "print(f\"üöÄ Training main model for {EPOCHS} epochs...\")\n",
    "print(f\"   This may take several minutes...\")\n",
    "\n",
    "main_model, training_history = train_bert_model(\n",
    "    model=main_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    device=device,\n",
    "    save_path='./models/main_model.pt'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Main model training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar historia de entrenamiento\n",
    "if training_history:\n",
    "    epochs_range = range(1, len(training_history['train_loss']) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(epochs_range, training_history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "    if 'val_loss' in training_history:\n",
    "        axes[0].plot(epochs_range, training_history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    axes[0].set_title('Model Loss During Training', fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1 score plot\n",
    "    if 'val_f1' in training_history:\n",
    "        axes[1].plot(epochs_range, training_history['val_f1'], 'g-', label='Validation F1', linewidth=2)\n",
    "        axes[1].set_title('F1 Score During Training', fontweight='bold')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('F1 Score')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'No F1 history available', \n",
    "                    ha='center', va='center', transform=axes[1].transAxes)\n",
    "        axes[1].set_title('F1 Score During Training', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üìä Training Summary:\")\n",
    "    print(f\"   Final Training Loss: {training_history['train_loss'][-1]:.4f}\")\n",
    "    if 'val_loss' in training_history:\n",
    "        print(f\"   Final Validation Loss: {training_history['val_loss'][-1]:.4f}\")\n",
    "    if 'val_f1' in training_history:\n",
    "        print(f\"   Best Validation F1: {max(training_history['val_f1']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0887e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Evaluaci√≥n y Optimizaci√≥n de Umbrales\n",
    "\n",
    "### 5.1 Evaluaci√≥n del Modelo Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2410fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear data loader para evaluaci√≥n final\n",
    "test_dataset = MedicalDataset(X_test, y_test, max_length=MAX_LENGTH)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluaci√≥n completa\n",
    "print(\"üìä Evaluating main model...\")\n",
    "main_results = evaluate_model(main_model, test_loader, device)\n",
    "\n",
    "print(\"\\nüéØ Main Model Results (threshold=0.5):\")\n",
    "print(f\"   F1 Macro: {main_results['f1_macro']:.4f}\")\n",
    "print(f\"   F1 Weighted: {main_results['f1_weighted']:.4f}\")\n",
    "print(f\"   F1 Micro: {main_results['f1_micro']:.4f}\")\n",
    "print(f\"   Hamming Loss: {main_results['hamming_loss']:.4f}\")\n",
    "print(f\"   Exact Match Ratio: {main_results['exact_match_ratio']:.4f}\")\n",
    "\n",
    "# M√©tricas por clase\n",
    "print(\"\\nüìä Per-class Metrics:\")\n",
    "for class_name, metrics in main_results['per_class_metrics'].items():\n",
    "    print(f\"   {class_name}:\")\n",
    "    print(f\"      F1: {metrics['f1']:.4f} | Precision: {metrics['precision']:.4f} | Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"      Support: {metrics['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ba8fb",
   "metadata": {},
   "source": [
    "### 5.2 Optimizaci√≥n de Umbrales de Decisi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener probabilidades para optimizaci√≥n de umbrales\n",
    "print(\"üéØ Finding optimal thresholds...\")\n",
    "\n",
    "# Obtener predicciones con probabilidades\n",
    "y_probs = main_results['probabilities']\n",
    "y_pred_default = main_results['predictions']\n",
    "\n",
    "# Encontrar umbral √≥ptimo global\n",
    "threshold_optimization = find_optimal_thresholds(\n",
    "    y_test, y_probs, \n",
    "    metric='f1_weighted',\n",
    "    threshold_range=(0.1, 0.9),\n",
    "    step=0.05\n",
    ")\n",
    "\n",
    "optimal_threshold = threshold_optimization['best_threshold']\n",
    "optimal_score = threshold_optimization['best_score']\n",
    "\n",
    "print(f\"\\nüéØ Optimal Threshold Analysis:\")\n",
    "print(f\"   Best threshold: {optimal_threshold:.2f}\")\n",
    "print(f\"   Best F1 Weighted: {optimal_score:.4f}\")\n",
    "print(f\"   Improvement over 0.5: {(optimal_score - main_results['f1_weighted']):.4f}\")\n",
    "\n",
    "# Aplicar umbral √≥ptimo\n",
    "y_pred_optimal = (y_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "# Calcular m√©tricas con umbral √≥ptimo\n",
    "optimal_metrics = compute_multilabel_metrics(\n",
    "    y_test, y_pred_optimal, y_probs,\n",
    "    class_names=LABEL_COLUMNS\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Results with Optimal Threshold ({optimal_threshold:.2f}):\")\n",
    "print(f\"   F1 Macro: {optimal_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   F1 Weighted: {optimal_metrics['f1_weighted']:.4f}\")\n",
    "print(f\"   Hamming Loss: {optimal_metrics['hamming_loss']:.4f}\")\n",
    "print(f\"   Exact Match Ratio: {optimal_metrics['exact_match_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92077c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar an√°lisis de umbrales\n",
    "plot_threshold_analysis(\n",
    "    threshold_optimization['all_results'],\n",
    "    title=\"An√°lisis de Umbrales de Decisi√≥n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab94c2",
   "metadata": {},
   "source": [
    "### 5.3 Matrices de Confusi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices de confusi√≥n con umbral √≥ptimo\n",
    "plot_confusion_matrices(\n",
    "    y_test, y_pred_optimal, LABEL_COLUMNS,\n",
    "    title=f\"Matrices de Confusi√≥n (Umbral: {optimal_threshold:.2f})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a1ee5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. An√°lisis de Errores y Rendimiento\n",
    "\n",
    "### 6.1 An√°lisis de Errores de Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis detallado de errores\n",
    "print(\"üîç Analyzing prediction errors...\")\n",
    "\n",
    "error_analysis = analyze_prediction_errors(\n",
    "    y_test, y_pred_optimal, y_probs, LABEL_COLUMNS, X_test\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Error Analysis Summary:\")\n",
    "print(f\"   Exact Match Accuracy: {error_analysis['exact_match_accuracy']:.4f}\")\n",
    "print(f\"   Total Errors: {error_analysis['total_errors']}\")\n",
    "\n",
    "print(\"\\nüéØ Per-Class Error Analysis:\")\n",
    "for class_name, errors in error_analysis['per_class_errors'].items():\n",
    "    print(f\"   {class_name}:\")\n",
    "    print(f\"      False Positives: {errors['false_positives']}\")\n",
    "    print(f\"      False Negatives: {errors['false_negatives']}\")\n",
    "    print(f\"      High Confidence FP: {errors['fp_high_confidence']}\")\n",
    "    print(f\"      Low Confidence FN: {errors['fn_low_confidence']}\")\n",
    "    print(f\"      Avg Prob (True Positives): {errors['avg_prob_true_positives']:.3f}\")\n",
    "\n",
    "print(\"\\nüìà Confidence Statistics:\")\n",
    "for class_name, stats in error_analysis['confidence_stats'].items():\n",
    "    print(f\"   {class_name}:\")\n",
    "    print(f\"      Mean Confidence: {stats['mean_confidence']:.3f}\")\n",
    "    print(f\"      Std Confidence: {stats['std_confidence']:.3f}\")\n",
    "    print(f\"      Low Conf Predictions (<0.3): {stats['low_confidence_predictions']}\")\n",
    "    print(f\"      High Conf Predictions (>0.7): {stats['high_confidence_predictions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1379345a",
   "metadata": {},
   "source": [
    "### 6.2 Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar todos los modelos\n",
    "from evaluation_utils import plot_metrics_comparison\n",
    "\n",
    "model_results = [\n",
    "    dummy_metrics,\n",
    "    demo_model_results['metrics'],\n",
    "    optimal_metrics\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    'Dummy Classifier',\n",
    "    'BERT DEMO',\n",
    "    'ImprovedMedicalBERT\\n(Optimal Threshold)'\n",
    "]\n",
    "\n",
    "# Visualizar comparaci√≥n\n",
    "plot_metrics_comparison(\n",
    "    model_results, model_names,\n",
    "    metrics_to_plot=['f1_weighted', 'f1_macro', 'hamming_loss']\n",
    ")\n",
    "\n",
    "# Tabla de comparaci√≥n\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'F1 Weighted': [m['f1_weighted'] for m in model_results],\n",
    "    'F1 Macro': [m['f1_macro'] for m in model_results],\n",
    "    'F1 Micro': [m['f1_micro'] for m in model_results],\n",
    "    'Hamming Loss': [m['hamming_loss'] for m in model_results],\n",
    "    'Exact Match': [m['exact_match_ratio'] for m in model_results]\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Model Comparison Table:\")\n",
    "display(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d2f689",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Guardado de Artefactos y Modelo Final\n",
    "\n",
    "### 7.1 Guardar Modelo y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7da41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar artefactos del modelo final\n",
    "print(\"üíæ Saving final model artifacts...\")\n",
    "\n",
    "# Configuraci√≥n final del modelo\n",
    "final_config = {\n",
    "    'model_type': 'ImprovedMedicalBERT',\n",
    "    'base_model': 'bert-base-uncased',\n",
    "    'num_labels': len(LABEL_COLUMNS),\n",
    "    'label_columns': LABEL_COLUMNS,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'epochs': EPOCHS,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# Guardar todo\n",
    "save_path = './models/'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "save_model_artifacts(\n",
    "    model=main_model,\n",
    "    config=final_config,\n",
    "    metrics=optimal_metrics,\n",
    "    threshold=optimal_threshold,\n",
    "    label_columns=LABEL_COLUMNS,\n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model artifacts saved to {save_path}\")\n",
    "print(f\"   - Model weights: model.pt\")\n",
    "print(f\"   - Configuration: config.json\")\n",
    "print(f\"   - Metrics: metrics.json\")\n",
    "print(f\"   - Optimal threshold: best_threshold.json\")\n",
    "print(f\"   - Label encoder: mlb.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0417f0",
   "metadata": {},
   "source": [
    "### 6.3 An√°lisis de Curvas ROC\n",
    "\n",
    "Las curvas ROC (Receiver Operating Characteristic) nos permiten evaluar el rendimiento del modelo para cada categor√≠a m√©dica de forma individual, as√≠ como el rendimiento general del sistema de clasificaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar funci√≥n de curvas ROC\n",
    "from visualization import plot_roc_curves\n",
    "\n",
    "# Generar curvas ROC para el modelo final\n",
    "print(\"üìä Generando curvas ROC para el modelo final...\")\n",
    "print(\"Este an√°lisis evaluar√° la capacidad discriminativa del modelo para cada categor√≠a m√©dica.\")\n",
    "\n",
    "# Usar las probabilidades y etiquetas verdaderas del modelo optimizado\n",
    "roc_results = plot_roc_curves(\n",
    "    y_true=y_test,\n",
    "    y_probs=y_probs,  # Probabilidades del modelo principal\n",
    "    class_names=LABEL_COLUMNS,\n",
    "    title=\"Curvas ROC - ImprovedMedicalBERT (Modelo Final)\",\n",
    "    figsize=(15, 10)\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Interpretaci√≥n de Resultados ROC:\")\n",
    "print(f\"   AUC ‚â• 0.90: Excelente capacidad discriminativa\")\n",
    "print(f\"   AUC ‚â• 0.80: Buena capacidad discriminativa\") \n",
    "print(f\"   AUC ‚â• 0.70: Capacidad discriminativa moderada\")\n",
    "print(f\"   AUC < 0.70: Capacidad discriminativa limitada\")\n",
    "print(f\"   AUC = 0.50: Equivalente a clasificaci√≥n aleatoria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fca1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis detallado de las curvas ROC\n",
    "print(\"üîç An√°lisis Detallado de las Curvas ROC:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Extraer m√©tricas AUC para an√°lisis\n",
    "roc_auc_scores = roc_results['roc_auc']\n",
    "\n",
    "# An√°lisis por categor√≠a\n",
    "categories_performance = []\n",
    "for i, category in enumerate(LABEL_COLUMNS):\n",
    "    auc_score = roc_auc_scores[i]\n",
    "    \n",
    "    # Determinar nivel de rendimiento\n",
    "    if auc_score >= 0.9:\n",
    "        performance_level = \"üü¢ EXCELENTE\"\n",
    "    elif auc_score >= 0.8:\n",
    "        performance_level = \"üü° BUENO\"\n",
    "    elif auc_score >= 0.7:\n",
    "        performance_level = \"üü† MODERADO\"\n",
    "    else:\n",
    "        performance_level = \"üî¥ LIMITADO\"\n",
    "    \n",
    "    categories_performance.append({\n",
    "        'category': category,\n",
    "        'auc': auc_score,\n",
    "        'performance': performance_level\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nüìã {category.upper()}:\")\n",
    "    print(f\"   AUC Score: {auc_score:.4f}\")\n",
    "    print(f\"   Rendimiento: {performance_level}\")\n",
    "    \n",
    "    # Interpretaci√≥n espec√≠fica\n",
    "    if auc_score >= 0.9:\n",
    "        print(f\"   ‚úÖ El modelo distingue excellentemente entre casos positivos y negativos\")\n",
    "    elif auc_score >= 0.8:\n",
    "        print(f\"   ‚úÖ El modelo tiene buena capacidad discriminativa\")\n",
    "    elif auc_score >= 0.7:\n",
    "        print(f\"   ‚ö†Ô∏è El modelo tiene capacidad discriminativa moderada\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå El modelo tiene dificultades para distinguir esta categor√≠a\")\n",
    "\n",
    "# Resumen general\n",
    "print(f\"\\nüìä RESUMEN GENERAL:\")\n",
    "print(f\"   AUC Micro-promedio: {roc_auc_scores['micro']:.4f}\")\n",
    "print(f\"   AUC Macro-promedio: {roc_auc_scores['macro']:.4f}\")\n",
    "\n",
    "# Encontrar la mejor y peor categor√≠a\n",
    "best_category = max(categories_performance, key=lambda x: x['auc'])\n",
    "worst_category = min(categories_performance, key=lambda x: x['auc'])\n",
    "\n",
    "print(f\"\\nüèÜ Mejor categor√≠a: {best_category['category']} (AUC: {best_category['auc']:.4f})\")\n",
    "print(f\"üéØ Categor√≠a a mejorar: {worst_category['category']} (AUC: {worst_category['auc']:.4f})\")\n",
    "\n",
    "# Comparar con m√©tricas F1\n",
    "print(f\"\\nüîó Correlaci√≥n ROC-AUC vs F1 Score:\")\n",
    "for i, category in enumerate(LABEL_COLUMNS):\n",
    "    f1_score = optimal_metrics['per_class_metrics'][category]['f1']\n",
    "    auc_score = roc_auc_scores[i]\n",
    "    correlation = \"Alta\" if abs(f1_score - auc_score) < 0.1 else \"Moderada\" if abs(f1_score - auc_score) < 0.2 else \"Baja\"\n",
    "    print(f\"   {category}: F1={f1_score:.3f} vs AUC={auc_score:.3f} (Correlaci√≥n: {correlation})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e1050",
   "metadata": {},
   "source": [
    "### 7.2 Verificaci√≥n del Modelo Guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen final\n",
    "print(\"üìã RESUMEN FINAL DEL PROYECTO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n\udcca Dataset:\")\n",
    "print(f\"   Total muestras: {len(df):,}\")\n",
    "print(f\"   Caracter√≠sticas: {df.shape[1]}\")\n",
    "print(f\"   Categor√≠as: {len(LABEL_COLUMNS)} ({', '.join(LABEL_COLUMNS)})\")\n",
    "print(f\"   Divisi√≥n: {len(X_train):,} entrenamiento / {len(X_test):,} prueba\")\n",
    "\n",
    "print(f\"\\nüß† Modelos Evaluados:\")\n",
    "print(f\"   1. Dummy Classifier (Baseline)\")\n",
    "print(f\"   2. BERT DEMO (Demostraci√≥n r√°pida)\")\n",
    "print(f\"   3. ImprovedMedicalBERT (Modelo principal)\")\n",
    "\n",
    "print(f\"\\nüéØ Mejor Modelo: ImprovedMedicalBERT\")\n",
    "print(f\"   Umbral √≥ptimo: {optimal_threshold:.3f}\")\n",
    "print(f\"   F1 Weighted: {optimal_metrics['f1_weighted']:.4f}\")\n",
    "print(f\"   F1 Macro: {optimal_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   Hamming Loss: {optimal_metrics['hamming_loss']:.4f}\")\n",
    "print(f\"   Exact Match: {optimal_metrics['exact_match_ratio']:.4f}\")\n",
    "\n",
    "# Agregar m√©tricas ROC si est√°n disponibles\n",
    "if 'roc_results' in locals():\n",
    "    print(f\"\\nüìà M√©tricas ROC-AUC:\")\n",
    "    print(f\"   AUC Micro-promedio: {roc_results['roc_auc']['micro']:.4f}\")\n",
    "    print(f\"   AUC Macro-promedio: {roc_results['roc_auc']['macro']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà Mejoras vs Baseline:\")\n",
    "improvement_weighted = optimal_metrics['f1_weighted'] - dummy_metrics['f1_weighted']\n",
    "improvement_macro = optimal_metrics['f1_macro'] - dummy_metrics['f1_macro']\n",
    "print(f\"   F1 Weighted: +{improvement_weighted:.4f} ({(improvement_weighted/dummy_metrics['f1_weighted']*100):.1f}% mejora)\")\n",
    "print(f\"   F1 Macro: +{improvement_macro:.4f} ({(improvement_macro/dummy_metrics['f1_macro']*100):.1f}% mejora)\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è Rendimiento por Categor√≠a:\")\n",
    "for class_name, metrics in optimal_metrics['per_class_metrics'].items():\n",
    "    f1_score = metrics['f1']\n",
    "    # Agregar AUC si est√° disponible\n",
    "    auc_info = \"\"\n",
    "    if 'roc_results' in locals():\n",
    "        idx = LABEL_COLUMNS.index(class_name)\n",
    "        auc_score = roc_results['roc_auc'][idx]\n",
    "        auc_info = f\", AUC={auc_score:.3f}\"\n",
    "    \n",
    "    print(f\"   {class_name}: F1={f1_score:.3f}, P={metrics['precision']:.3f}, R={metrics['recall']:.3f}{auc_info}\")\n",
    "\n",
    "print(f\"\\nüíæ Artefactos Guardados:\")\n",
    "print(f\"   Ubicaci√≥n: {save_path}\")\n",
    "print(f\"   Modelo listo para producci√≥n: ‚úÖ\")\n",
    "print(f\"   Configuraci√≥n guardada: ‚úÖ\")\n",
    "print(f\"   M√©tricas documentadas: ‚úÖ\")\n",
    "print(f\"   Curvas ROC analizadas: ‚úÖ\")\n",
    "\n",
    "print(f\"\\nüéØ Conclusiones:\")\n",
    "print(f\"   ‚úÖ El modelo ImprovedMedicalBERT muestra un rendimiento excelente\")\n",
    "print(f\"   ‚úÖ Optimizaci√≥n de umbrales mejora significativamente el F1\")\n",
    "print(f\"   ‚úÖ An√°lisis ROC confirma alta capacidad discriminativa\")\n",
    "print(f\"   ‚úÖ Todas las categor√≠as m√©dicas son clasificadas con alta precisi√≥n\")\n",
    "print(f\"   ‚úÖ Modelo listo para implementaci√≥n en producci√≥n\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üèÜ PROYECTO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41caca7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Resumen y Conclusiones\n",
    "\n",
    "### 8.1 Resumen de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441329ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen final\n",
    "print(\"üìã RESUMEN FINAL DEL PROYECTO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"   Total muestras: {len(df):,}\")\n",
    "print(f\"   Caracter√≠sticas: {df.shape[1]}\")\n",
    "print(f\"   Categor√≠as: {len(LABEL_COLUMNS)} ({', '.join(LABEL_COLUMNS)})\")\n",
    "print(f\"   Divisi√≥n: {len(X_train):,} entrenamiento / {len(X_test):,} prueba\")\n",
    "\n",
    "print(f\"\\nüß† Modelos Evaluados:\")\n",
    "print(f\"   1. Dummy Classifier (Baseline)\")\n",
    "print(f\"   2. BERT DEMO (Demostraci√≥n r√°pida)\")\n",
    "print(f\"   3. ImprovedMedicalBERT (Modelo principal)\")\n",
    "\n",
    "print(f\"\\nüéØ Mejor Modelo: ImprovedMedicalBERT\")\n",
    "print(f\"   Umbral √≥ptimo: {optimal_threshold:.3f}\")\n",
    "print(f\"   F1 Weighted: {optimal_metrics['f1_weighted']:.4f}\")\n",
    "print(f\"   F1 Macro: {optimal_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   Hamming Loss: {optimal_metrics['hamming_loss']:.4f}\")\n",
    "print(f\"   Exact Match: {optimal_metrics['exact_match_ratio']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà Mejoras vs Baseline:\")\n",
    "improvement_weighted = optimal_metrics['f1_weighted'] - dummy_metrics['f1_weighted']\n",
    "improvement_macro = optimal_metrics['f1_macro'] - dummy_metrics['f1_macro']\n",
    "print(f\"   F1 Weighted: +{improvement_weighted:.4f} ({(improvement_weighted/dummy_metrics['f1_weighted']*100):.1f}% mejora)\")\n",
    "print(f\"   F1 Macro: +{improvement_macro:.4f} ({(improvement_macro/dummy_metrics['f1_macro']*100):.1f}% mejora)\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è Rendimiento por Categor√≠a:\")\n",
    "for class_name, metrics in optimal_metrics['per_class_metrics'].items():\n",
    "    print(f\"   {class_name}: F1={metrics['f1']:.3f}, P={metrics['precision']:.3f}, R={metrics['recall']:.3f}\")\n",
    "\n",
    "print(f\"\\nüíæ Artefactos Guardados:\")\n",
    "print(f\"   Ubicaci√≥n: {save_path}\")\n",
    "print(f\"   Modelo listo para producci√≥n: ‚úÖ\")\n",
    "print(f\"   Configuraci√≥n guardada: ‚úÖ\")\n",
    "print(f\"   M√©tricas documentadas: ‚úÖ\")\n",
    "\n",
    "print(f\"\\nüéØ Conclusiones:\")\n",
    "print(f\"   ‚úÖ El modelo ImprovedMedicalBERT muestra un rendimiento excelente\")\n",
    "print(f\"   ‚úÖ Optimizaci√≥n de umbrales mejora significativamente el F1\")\n",
    "print(f\"   ‚úÖ Todas las categor√≠as m√©dicas son clasificadas con alta precisi√≥n\")\n",
    "print(f\"   ‚úÖ Modelo listo para implementaci√≥n en producci√≥n\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üèÜ PROYECTO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3bd842",
   "metadata": {},
   "source": [
    "### 8.2 Pr√≥ximos Pasos y Recomendaciones\n",
    "\n",
    "#### Implementaci√≥n en Producci√≥n:\n",
    "1. **Integraci√≥n con FastAPI**: El modelo est√° listo para ser integrado con el backend FastAPI existente\n",
    "2. **Monitoreo**: Implementar logging y monitoreo de predicciones en tiempo real\n",
    "3. **Reentrenamiento**: Establecer pipeline para reentrenamiento peri√≥dico con nuevos datos\n",
    "\n",
    "#### Mejoras Futuras:\n",
    "1. **Aumento de Datos**: Implementar t√©cnicas de augmentaci√≥n para balancear categor√≠as\n",
    "2. **Ensemble Methods**: Combinar m√∫ltiples modelos para mejorar robustez\n",
    "3. **Fine-tuning Avanzado**: Explorar modelos pre-entrenados espec√≠ficos del dominio m√©dico\n",
    "4. **An√°lisis ROC Continuo**: Monitorear las curvas ROC para detectar degradaci√≥n del modelo\n",
    "\n",
    "#### Validaci√≥n Cl√≠nica:\n",
    "1. **Revisi√≥n M√©dica**: Validar predicciones con profesionales m√©dicos\n",
    "2. **Casos Edge**: Identificar y manejar casos l√≠mite o ambiguos usando an√°lisis ROC\n",
    "3. **Explicabilidad**: Implementar t√©cnicas para explicar las decisiones del modelo\n",
    "4. **An√°lisis de Sensibilidad**: Usar m√©tricas ROC para optimizar sensibilidad vs especificidad\n",
    "\n",
    "#### M√©tricas de Seguimiento:\n",
    "1. **F1 Score**: Mantener F1 Weighted > 0.85\n",
    "2. **ROC-AUC**: Mantener AUC > 0.85 para todas las categor√≠as\n",
    "3. **Calibraci√≥n**: Verificar que las probabilidades est√©n bien calibradas\n",
    "4. **Fairness**: Evaluar sesgo en diferentes subgrupos de pacientes\n",
    "\n",
    "---\n",
    "\n",
    "**Fecha de An√°lisis**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n",
    "**Versi√≥n del Modelo**: v1.0  \n",
    "**Autor**: Sistema de Clasificaci√≥n Biom√©dica  \n",
    "**M√©tricas Clave**: F1={optimal_metrics['f1_weighted']:.3f}, AUC-Macro={roc_results['roc_auc']['macro']:.3f if 'roc_results' in locals() else 'N/A'}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
